{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon_functions - python script with all the polygon helper functions\n",
    "from polygon_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_database = pd.read_csv('data/move_data_with_fundamentals.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_database = move_database.sort_values(by = '1', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare databases\n",
    "basic_database = move_database[['0', \n",
    "                                '1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_database.columns = ['Stock', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-dfacf129f539>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  basic_database['Date'] = [pd.Timestamp(year = pd.Timestamp(date).year,\n"
     ]
    }
   ],
   "source": [
    "basic_database['Date'] = [pd.Timestamp(year = pd.Timestamp(date).year,\n",
    "                                       month = pd.Timestamp(date).month,\n",
    "                                       day = pd.Timestamp(date).day,\n",
    "                                       hour = 9,\n",
    "                                       minute = 30,\n",
    "                                       tz = 'America/New_York') for date in basic_database['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_fundamentals = move_database[['Market Capitalization',\n",
    " 'Current Liabilities',\n",
    " 'Shares',\n",
    " 'Cash',\n",
    " 'Operating Expenses',\n",
    " 'Current Ratio',\n",
    " 'PE Ratio',\n",
    " 'Earnings/Share',\n",
    " 'Debt/Equity',\n",
    " 'Debt',\n",
    " 'Current Debt',\n",
    " 'Interest Expense',\n",
    " 'Revenue',\n",
    " 'Price/Sales',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "offering_data = move_database[['Num. Active ATMs (all time)',\n",
    " 'Num. Active 424s (all time)',\n",
    " 'Num. Active 424B5s (past year)',\n",
    " 'Num. Active 424B3s (past year)',\n",
    " 'Shares Raised in the Past Year',\n",
    " 'Dollars Raised in the Past Year',\n",
    " 'Current Offering (shares)',\n",
    " 'Current Offering (cash)',\n",
    " 'ATM Present']]\n",
    "\n",
    "offering_data['Current Offering (cash)'].loc[offering_data[offering_data['Current Offering (cash)'] < 1000].index] = 0.0\n",
    "offering_data['ATM Present'].loc[offering_data[offering_data['Current Offering (cash)'] < 1000].index] = False\n",
    "offering_data['Current Offering (shares)'].loc[offering_data[offering_data['Current Offering (shares)'] < 1000].index] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morning_low(stock, date):\n",
    "    try:\n",
    "        date = pd.Timestamp(date)\n",
    "        date = pd.Timestamp(year = date.year,\n",
    "                            month = date.month, \n",
    "                            day = date.day,\n",
    "                            hour = 9,\n",
    "                            minute = 30,\n",
    "                            tz = 'America/New_York')\n",
    "        morning_date = pd.Timestamp(year = date.year,\n",
    "                            month = date.month, \n",
    "                            day = date.day,\n",
    "                            hour = 12,\n",
    "                            minute = 0,\n",
    "                            tz = 'America/New_York')\n",
    "        stock_data = get_data_for_stock(stock, date)\n",
    "        stock_data.index = [pd.Timestamp(ts).tz_localize('America/New_York').tz_convert('America/New_York') for ts in stock_data.index]\n",
    "        morning_LOD = stock_data[(stock_data.index >= date) & (stock_data.index <= morning_date)]['Low'].min()\n",
    "        open_price = stock_data.loc[date, 'Close']\n",
    "        return (morning_LOD - open_price) / open_price\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_LODs = Parallel(12, 'loky', verbose = 10)(delayed(get_morning_low)(stock, date) for stock, date in move_data[['0', '1']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_action_database = move_database[['open_price', 'pm_open', 'hi_price', 'Prior Day Price Action Trend', 'Premarket Move Change Classification', 'Premarket Move Time Classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_action_database.columns = ['Open Price', 'PM Beginning Price', 'PM High Price', 'Prior Day Price Action Trend', 'Premarket Move Change Classification', 'Premarket Move Time Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_fundamentals_DB = move_database[[ 'Shares Outstanding',\n",
    " 'Float Shares',\n",
    " 'Float Percentage',\n",
    " 'IO%',\n",
    " 'Insider%',\n",
    " 'Months Left',\n",
    " 'Accumulated Deficit',\n",
    " 'Net Working Capital']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_database.to_csv('data/base_data.csv')\n",
    "basic_fundamentals.to_csv('data/basic_fundamentals.csv')\n",
    "offering_data.to_csv('data/offering_data.csv')\n",
    "price_action_database.to_csv('data/PA_database.csv')\n",
    "uncommon_fundamentals_DB.to_csv('data/uncommon_fundamentals_database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=12)]: Done 289 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=12)]: Done 314 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=12)]: Done 368 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=12)]: Done 397 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=12)]: Done 457 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=12)]: Done 488 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=12)]: Done 521 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=12)]: Done 554 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=12)]: Done 589 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=12)]: Done 661 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=12)]: Done 698 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=12)]: Done 737 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=12)]: Done 817 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=12)]: Done 901 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=12)]: Done 944 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=12)]: Done 989 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=12)]: Done 1034 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=12)]: Done 1081 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=12)]: Done 1128 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=12)]: Done 1177 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done 1277 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 1328 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 1381 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 1441 out of 1441 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "def get_data_for_stock1d(stock, start_date, end_date, tz_origin = 'America/Chicago', tz_to_convert = 'America/New_York', token = 'AKMZJGOJ8KO8NB5P32VG'):\n",
    "    try:\n",
    "        start_date = pd.Timestamp(pd.Timestamp(start_date).date())\n",
    "        end_date = pd.Timestamp(pd.Timestamp(end_date).date())\n",
    "        request = 'https://api.polygon.io/v2/aggs/ticker/{}/range/1/day/{}/{}?unadjusted=true&sort=asc&apiKey={}'.format(stock.upper(), str(start_date.date()), str(end_date.date()), token)\n",
    "        raw_data = json.loads(requests.get(request).text)\n",
    "        raw_data = pd.DataFrame(raw_data['results'])\n",
    "        raw_data['Timestamp'] = [pd.Timestamp(datetime.datetime.fromtimestamp(t/1000)) for t in raw_data['t']]\n",
    "        raw_data['Hour'] = [date.hour for date in raw_data['Timestamp']]\n",
    "        raw_data['Minute'] = [date.minute for date in raw_data['Timestamp']]\n",
    "        raw_data = raw_data[['v', 'o', 'c', 'h', 'l', 'Timestamp']]\n",
    "        raw_data.columns = ['Volume', 'Open', 'Close', 'High', 'Low', 'Ts']\n",
    "        raw_data = raw_data.set_index('Ts')\n",
    "        return raw_data\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "#         print('No data found for {} on {}'.format(stock, start_date))\n",
    "        pass\n",
    "def get_60d_high(stock, date):\n",
    "    date = pd.Timestamp(date)\n",
    "    return get_data_for_stock1d(stock, date - pd.Timedelta('1 day'), date + pd.Timedelta('1 day'))['High'].max()\n",
    "def get_dump_data(i):\n",
    "# for i in move_data.index:\n",
    "    try:\n",
    "        stock = move_database.loc[i, '0']\n",
    "        date = move_database.loc[i, '1']\n",
    "        date = pd.Timestamp(date)\n",
    "        date = pd.Timestamp(year = date.year,\n",
    "                             month = date.month,\n",
    "                             day = date.day,\n",
    "                            hour = 9, \n",
    "                            minute = 30,\n",
    "                            tz = 'America/New_York')\n",
    "        stock_data = get_data_for_stock1d(stock, date - pd.Timedelta('10000 days'), date)\n",
    "        stock_data['Premarket Change'] = (stock_data['Open'] - stock_data['Close'].shift(1)) / stock_data['Close'].shift(1)\n",
    "        stock_data['Candle Move'] = (stock_data['Close'] - stock_data['Open']) / stock_data['Open']\n",
    "        dumps = stock_data[stock_data['Premarket Change'] > 0.1]\n",
    "        failure_rate = len(dumps[dumps['Candle Move'] < 0]) / len(dumps)\n",
    "        try:\n",
    "            average_dump = dumps[dumps['Candle Move'] < 0]['Candle Move'].mean()\n",
    "        except:\n",
    "            average_dump = np.nan\n",
    "        try:\n",
    "            average_success = dumps[dumps['Candle Move'] > 0]['Candle Move'].mean()\n",
    "        except:\n",
    "            average_success = np.nan\n",
    "        splits = get_stock_splits(stock, date)\n",
    "        return {'Failure Rate': failure_rate,\n",
    "                'Average Dump': average_dump,\n",
    "                'Average Success': average_success,\n",
    "                '# Dumps': len(dumps),\n",
    "                'Splits': splits}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {'Failure Rate': np.nan,\n",
    "                'Average Dump': np.nan,\n",
    "                'Average Success': np.nan,\n",
    "                '# Dumps': 0,\n",
    "                'Splits': np.nan}\n",
    "dump_data = Parallel(12, 'loky', verbose = 10)(delayed(get_dump_data)(i) for i in move_database.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data = pd.DataFrame(dump_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Failure Rate</th>\n",
       "      <th>Average Dump</th>\n",
       "      <th>Average Success</th>\n",
       "      <th># Dumps</th>\n",
       "      <th>Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.108506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>-0.088522</td>\n",
       "      <td>0.052873</td>\n",
       "      <td>24</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.117393</td>\n",
       "      <td>0.382978</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.079964</td>\n",
       "      <td>0.224270</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.022673</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.106392</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>28</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.088972</td>\n",
       "      <td>0.110870</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.073757</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>-0.096605</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Failure Rate  Average Dump  Average Success  # Dumps    Splits\n",
       "0         1.000000     -0.108506              NaN        3  0.033333\n",
       "1         0.791667     -0.088522         0.052873       24  0.125000\n",
       "2         0.700000     -0.117393         0.382978       20  1.000000\n",
       "3         0.750000     -0.079964         0.224270       16  1.000000\n",
       "4         0.333333     -0.022673         0.026294        3  1.000000\n",
       "...            ...           ...              ...      ...       ...\n",
       "1436      0.750000     -0.106392         0.219656       28  0.100000\n",
       "1437      0.833333     -0.088972         0.110870        6  1.000000\n",
       "1438      0.833333     -0.073757         0.441341        6  1.000000\n",
       "1439      0.928571     -0.096605         0.113971       14  1.000000\n",
       "1440      0.500000     -0.015789         0.054545        2  4.000000\n",
       "\n",
       "[1441 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_data.to_csv('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
